{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\seedling_labels_with_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m image_folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mseedling_labels_with_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Loads labels\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(image_folder_path)\n\u001b[0;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPos\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_expert\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\seedling_labels_with_features.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Change the working directory to the parent directory of the current directory\n",
    "os.chdir(os.path.join(current_dir, '..'))\n",
    "# Enter path to the data_fusion_guest_lecture file\n",
    "image_folder_path = 'data/seedling_labels_with_features.csv'\n",
    "\n",
    "# Loads labels\n",
    "df = pd.read_csv(image_folder_path)\n",
    "\n",
    "df = df.drop(columns=['Pos','average_expert'])\n",
    "df = df.iloc[:, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by the 'Rfid' column\n",
    "groups = df.groupby('Rfid')\n",
    "\n",
    "# create separate dataframes for each group and drop the 'Rfid' column\n",
    "dfs = []\n",
    "i = 1\n",
    "for _, group_data in groups:\n",
    "    df_name = f\"df_{i}\"\n",
    "    globals()[df_name] = group_data.drop('Rfid', axis=1)\n",
    "    dfs.append(globals()[df_name] )\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    673\n",
       "0    321\n",
       "Name: expert_binary, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['expert_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n",
    "\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('binary_accuracy', 0.67227834), ('precision', 0.6719101), ('recall', 1.0), ('loss', 0.64619756), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  3, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.635824), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  4, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.62593406), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  5, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.61646146), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  6, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.6073237), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  7, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5984809), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  8, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.58990157), ('num_examples', 891), ('num_batches', 8)])\n",
      "round  9, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.58152884), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 10, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.57337844), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 11, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.56548965), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 12, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5579162), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 13, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5506719), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 14, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.54368824), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 15, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.53693724), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 16, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5304239), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 17, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.52415365), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 18, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.51812625), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 19, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.51239336), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 20, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5069387), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 21, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.5017781), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 22, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.49688992), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 23, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.4921889), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 24, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.4876424), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 25, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.483222), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 26, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.47892895), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 27, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.4747283), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 28, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.47057685), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 29, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.46648988), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 30, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.46242553), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 31, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.45835382), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 32, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.4542439), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 33, metrics=OrderedDict([('binary_accuracy', 0.671156), ('precision', 0.671156), ('recall', 1.0), ('loss', 0.45006564), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 34, metrics=OrderedDict([('binary_accuracy', 0.67227834), ('precision', 0.6719101), ('recall', 1.0), ('loss', 0.44584224), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 35, metrics=OrderedDict([('binary_accuracy', 0.67901236), ('precision', 0.6764706), ('recall', 1.0), ('loss', 0.44158772), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 36, metrics=OrderedDict([('binary_accuracy', 0.6924804), ('precision', 0.6857798), ('recall', 1.0), ('loss', 0.4373035), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 37, metrics=OrderedDict([('binary_accuracy', 0.71268237), ('precision', 0.7002342), ('recall', 1.0), ('loss', 0.4330219), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 38, metrics=OrderedDict([('binary_accuracy', 0.7373737), ('precision', 0.71875), ('recall', 1.0), ('loss', 0.42872587), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 39, metrics=OrderedDict([('binary_accuracy', 0.7598204), ('precision', 0.73703706), ('recall', 0.99832773), ('loss', 0.4244206), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 40, metrics=OrderedDict([('binary_accuracy', 0.78002244), ('precision', 0.7537879), ('recall', 0.99832773), ('loss', 0.42012486), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 41, metrics=OrderedDict([('binary_accuracy', 0.7979798), ('precision', 0.7693299), ('recall', 0.99832773), ('loss', 0.41585064), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 42, metrics=OrderedDict([('binary_accuracy', 0.8103255), ('precision', 0.78039217), ('recall', 0.99832773), ('loss', 0.41155887), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 43, metrics=OrderedDict([('binary_accuracy', 0.81593716), ('precision', 0.78552634), ('recall', 0.99832773), ('loss', 0.4072167), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 44, metrics=OrderedDict([('binary_accuracy', 0.8249158), ('precision', 0.79388297), ('recall', 0.99832773), ('loss', 0.40280682), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 45, metrics=OrderedDict([('binary_accuracy', 0.8294052), ('precision', 0.7989276), ('recall', 0.9966555), ('loss', 0.3983285), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 46, metrics=OrderedDict([('binary_accuracy', 0.83164984), ('precision', 0.8010753), ('recall', 0.9966555), ('loss', 0.39379248), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 47, metrics=OrderedDict([('binary_accuracy', 0.83838385), ('precision', 0.8075881), ('recall', 0.9966555), ('loss', 0.38916293), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 48, metrics=OrderedDict([('binary_accuracy', 0.84511787), ('precision', 0.8142077), ('recall', 0.9966555), ('loss', 0.38444987), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 49, metrics=OrderedDict([('binary_accuracy', 0.8473625), ('precision', 0.8164384), ('recall', 0.9966555), ('loss', 0.3796652), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 50, metrics=OrderedDict([('binary_accuracy', 0.8507295), ('precision', 0.8198074), ('recall', 0.9966555), ('loss', 0.37484488), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 51, metrics=OrderedDict([('binary_accuracy', 0.8518519), ('precision', 0.8209366), ('recall', 0.9966555), ('loss', 0.37001616), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 52, metrics=OrderedDict([('binary_accuracy', 0.85409653), ('precision', 0.8232044), ('recall', 0.9966555), ('loss', 0.36520013), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 53, metrics=OrderedDict([('binary_accuracy', 0.8529742), ('precision', 0.8229599), ('recall', 0.99498326), ('loss', 0.3604194), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 54, metrics=OrderedDict([('binary_accuracy', 0.85409653), ('precision', 0.8240997), ('recall', 0.99498326), ('loss', 0.35568458), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 55, metrics=OrderedDict([('binary_accuracy', 0.85409653), ('precision', 0.8240997), ('recall', 0.99498326), ('loss', 0.3510019), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 56, metrics=OrderedDict([('binary_accuracy', 0.8563412), ('precision', 0.8263889), ('recall', 0.99498326), ('loss', 0.34639016), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 57, metrics=OrderedDict([('binary_accuracy', 0.85746354), ('precision', 0.82753825), ('recall', 0.99498326), ('loss', 0.34185225), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 58, metrics=OrderedDict([('binary_accuracy', 0.8597082), ('precision', 0.82984656), ('recall', 0.99498326), ('loss', 0.33740607), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 59, metrics=OrderedDict([('binary_accuracy', 0.86083055), ('precision', 0.8310056), ('recall', 0.99498326), ('loss', 0.33305985), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 60, metrics=OrderedDict([('binary_accuracy', 0.86531985), ('precision', 0.83567417), ('recall', 0.99498326), ('loss', 0.3288058), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 61, metrics=OrderedDict([('binary_accuracy', 0.86868685), ('precision', 0.8401697), ('recall', 0.99331105), ('loss', 0.3246466), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 62, metrics=OrderedDict([('binary_accuracy', 0.87542087), ('precision', 0.8473609), ('recall', 0.99331105), ('loss', 0.3205794), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 63, metrics=OrderedDict([('binary_accuracy', 0.8821549), ('precision', 0.85569984), ('recall', 0.9916388), ('loss', 0.3165902), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 64, metrics=OrderedDict([('binary_accuracy', 0.88327724), ('precision', 0.857971), ('recall', 0.9899666), ('loss', 0.31267262), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 65, metrics=OrderedDict([('binary_accuracy', 0.88327724), ('precision', 0.857971), ('recall', 0.9899666), ('loss', 0.30882615), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 66, metrics=OrderedDict([('binary_accuracy', 0.88327724), ('precision', 0.85901165), ('recall', 0.9882943), ('loss', 0.30505884), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 67, metrics=OrderedDict([('binary_accuracy', 0.88776654), ('precision', 0.86403507), ('recall', 0.9882943), ('loss', 0.3013582), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 68, metrics=OrderedDict([('binary_accuracy', 0.88664424), ('precision', 0.8659794), ('recall', 0.9832776), ('loss', 0.29771146), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 69, metrics=OrderedDict([('binary_accuracy', 0.89001125), ('precision', 0.8698225), ('recall', 0.9832776), ('loss', 0.29412538), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 70, metrics=OrderedDict([('binary_accuracy', 0.89113355), ('precision', 0.87221396), ('recall', 0.98160535), ('loss', 0.29060245), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 71, metrics=OrderedDict([('binary_accuracy', 0.89450055), ('precision', 0.8761194), ('recall', 0.98160535), ('loss', 0.28715563), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 72, metrics=OrderedDict([('binary_accuracy', 0.8967452), ('precision', 0.8787425), ('recall', 0.98160535), ('loss', 0.2837782), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 73, metrics=OrderedDict([('binary_accuracy', 0.89786756), ('precision', 0.881203), ('recall', 0.9799331), ('loss', 0.28047624), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 74, metrics=OrderedDict([('binary_accuracy', 0.89786756), ('precision', 0.881203), ('recall', 0.9799331), ('loss', 0.27726015), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 75, metrics=OrderedDict([('binary_accuracy', 0.89786756), ('precision', 0.881203), ('recall', 0.9799331), ('loss', 0.27413404), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 76, metrics=OrderedDict([('binary_accuracy', 0.9046016), ('precision', 0.8892261), ('recall', 0.9799331), ('loss', 0.27110514), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 77, metrics=OrderedDict([('binary_accuracy', 0.9034792), ('precision', 0.88905776), ('recall', 0.9782609), ('loss', 0.26816115), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 78, metrics=OrderedDict([('binary_accuracy', 0.9034792), ('precision', 0.88905776), ('recall', 0.9782609), ('loss', 0.26531294), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 79, metrics=OrderedDict([('binary_accuracy', 0.91021323), ('precision', 0.89723927), ('recall', 0.9782609), ('loss', 0.26253748), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 80, metrics=OrderedDict([('binary_accuracy', 0.91021323), ('precision', 0.8984615), ('recall', 0.9765886), ('loss', 0.2598524), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 81, metrics=OrderedDict([('binary_accuracy', 0.91021323), ('precision', 0.89969134), ('recall', 0.9749164), ('loss', 0.2572589), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 82, metrics=OrderedDict([('binary_accuracy', 0.91021323), ('precision', 0.89969134), ('recall', 0.9749164), ('loss', 0.2547487), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 83, metrics=OrderedDict([('binary_accuracy', 0.9124579), ('precision', 0.9024768), ('recall', 0.9749164), ('loss', 0.25231242), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 84, metrics=OrderedDict([('binary_accuracy', 0.91358024), ('precision', 0.90387595), ('recall', 0.9749164), ('loss', 0.24993865), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 85, metrics=OrderedDict([('binary_accuracy', 0.9124579), ('precision', 0.9049844), ('recall', 0.9715719), ('loss', 0.24763279), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 86, metrics=OrderedDict([('binary_accuracy', 0.9124579), ('precision', 0.9049844), ('recall', 0.9715719), ('loss', 0.24540977), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 87, metrics=OrderedDict([('binary_accuracy', 0.9147026), ('precision', 0.9078125), ('recall', 0.9715719), ('loss', 0.24326733), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 88, metrics=OrderedDict([('binary_accuracy', 0.9158249), ('precision', 0.90923315), ('recall', 0.9715719), ('loss', 0.24120799), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 89, metrics=OrderedDict([('binary_accuracy', 0.9158249), ('precision', 0.90923315), ('recall', 0.9715719), ('loss', 0.2392228), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 90, metrics=OrderedDict([('binary_accuracy', 0.91694725), ('precision', 0.9106583), ('recall', 0.9715719), ('loss', 0.23731548), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 91, metrics=OrderedDict([('binary_accuracy', 0.9180696), ('precision', 0.9120879), ('recall', 0.9715719), ('loss', 0.23548675), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 92, metrics=OrderedDict([('binary_accuracy', 0.91694725), ('precision', 0.9119497), ('recall', 0.96989965), ('loss', 0.23374397), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 93, metrics=OrderedDict([('binary_accuracy', 0.91694725), ('precision', 0.9119497), ('recall', 0.96989965), ('loss', 0.2320685), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 94, metrics=OrderedDict([('binary_accuracy', 0.9180696), ('precision', 0.9146919), ('recall', 0.96822745), ('loss', 0.23046798), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 95, metrics=OrderedDict([('binary_accuracy', 0.9191919), ('precision', 0.91613925), ('recall', 0.96822745), ('loss', 0.22893758), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 96, metrics=OrderedDict([('binary_accuracy', 0.9225589), ('precision', 0.9191759), ('recall', 0.96989965), ('loss', 0.22747317), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 97, metrics=OrderedDict([('binary_accuracy', 0.9225589), ('precision', 0.9191759), ('recall', 0.96989965), ('loss', 0.22608328), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 98, metrics=OrderedDict([('binary_accuracy', 0.92368126), ('precision', 0.9206349), ('recall', 0.96989965), ('loss', 0.22474363), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 99, metrics=OrderedDict([('binary_accuracy', 0.9225589), ('precision', 0.92050874), ('recall', 0.96822745), ('loss', 0.22346531), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 100, metrics=OrderedDict([('binary_accuracy', 0.92368126), ('precision', 0.92197454), ('recall', 0.96822745), ('loss', 0.22223423), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 101, metrics=OrderedDict([('binary_accuracy', 0.9225589), ('precision', 0.9218501), ('recall', 0.9665552), ('loss', 0.22105075), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 102, metrics=OrderedDict([('binary_accuracy', 0.9214366), ('precision', 0.9217252), ('recall', 0.96488297), ('loss', 0.21991685), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 103, metrics=OrderedDict([('binary_accuracy', 0.92031425), ('precision', 0.9216), ('recall', 0.9632107), ('loss', 0.21882963), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 104, metrics=OrderedDict([('binary_accuracy', 0.92031425), ('precision', 0.9216), ('recall', 0.9632107), ('loss', 0.2177838), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 105, metrics=OrderedDict([('binary_accuracy', 0.9214366), ('precision', 0.9230769), ('recall', 0.9632107), ('loss', 0.21678303), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 106, metrics=OrderedDict([('binary_accuracy', 0.9214366), ('precision', 0.9244373), ('recall', 0.96153843), ('loss', 0.21582454), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 107, metrics=OrderedDict([('binary_accuracy', 0.9225589), ('precision', 0.9273021), ('recall', 0.9598662), ('loss', 0.21490264), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 108, metrics=OrderedDict([('binary_accuracy', 0.92368126), ('precision', 0.9288026), ('recall', 0.9598662), ('loss', 0.21401002), ('num_examples', 891), ('num_batches', 8)])\n",
      "round 109, metrics=OrderedDict([('binary_accuracy', 0.92368126), ('precision', 0.9288026), ('recall', 0.9598662), ('loss', 0.2131414), ('num_examples', 891), ('num_batches', 8)])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "def make_tf_dataset(dataframe, negative_ratio=None, batch_size=None):\n",
    "    dataset = dataframe\n",
    "\n",
    "    # Class balancing\n",
    "    pos_df = dataset[dataset['expert_binary'] == 1]\n",
    "    neg_df = dataset[dataset['expert_binary'] == 0]\n",
    "    \n",
    "    if negative_ratio:\n",
    "        neg_df = neg_df.iloc[random.sample(range(0, len(neg_df)), len(pos_df)*negative_ratio), :]\n",
    "    balanced_df = pd.concat([pos_df, neg_df], ignore_index=True, sort=False)\n",
    "\n",
    "    y = balanced_df.pop('expert_binary')\n",
    "    \n",
    "    # Dataset creation\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((balanced_df.values, y.to_frame().values))\n",
    "    dataset = dataset.shuffle(2048, seed=SEED)\n",
    "    if batch_size:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_data, val_data = [], []\n",
    "for client_data in dfs:\n",
    "    train_df, val_df = train_test_split(client_data, test_size=0.1, random_state=SEED)\n",
    "\n",
    "    # Scaling (Standardization actually hurts performance) \n",
    "    scaler = MinMaxScaler() \n",
    "    train_features = scaler.fit_transform(train_df.drop(['expert_binary'], axis=1))\n",
    "    val_features = scaler.transform(val_df.drop(['expert_binary'], axis=1))\n",
    "\n",
    "    train_df[train_df.columns.difference(['expert_binary'])] = train_features\n",
    "    val_df[val_df.columns.difference(['expert_binary'])] = val_features\n",
    "\n",
    "    # TF Datasets\n",
    "    train_data.append(make_tf_dataset(train_df, batch_size=BATCH_SIZE))\n",
    "    val_data.append(make_tf_dataset(val_df, batch_size=1))\n",
    "\n",
    "def input_spec():\n",
    "    return (\n",
    "        tf.TensorSpec([None, 6], tf.float64),           #you need to change the expected input shape based on the number of features we have\n",
    "        tf.TensorSpec([None, 1], tf.int64)\n",
    "    )\n",
    "\n",
    "def model_fn():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(6,)),   #you need to change the input shape based on the number of features we have\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=input_spec(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[BinaryAccuracy(), Precision(), Recall()])\n",
    "\n",
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "#print(training_process.initialize.type_signature.formatted_representation())\n",
    "\n",
    "train_state = training_process.initialize()\n",
    "\n",
    "NUM_ROUNDS = 110\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  result = training_process.next(train_state, train_data)\n",
    "  train_state = result.state\n",
    "  train_metrics = result.metrics['client_work']['train']\n",
    "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('eval',\n",
       "              OrderedDict([('binary_accuracy', 0.9223301),\n",
       "                           ('precision', 0.9350649),\n",
       "                           ('recall', 0.96),\n",
       "                           ('loss', 0.16753183),\n",
       "                           ('num_examples', 103),\n",
       "                           ('num_batches', 103)]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated_metrics = evaluator(training_process.get_model_weights(train_state), val_data)\n",
    "federated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[0].concatenate(train_data[1])\n",
    "val_data = val_data[0].concatenate(val_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 0.7139 - binary_accuracy: 0.3333 - precision: 0.5854 - recall: 0.1529    \n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6638 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6207 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5834 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5536 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5292 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5116 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4982 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4878 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4796 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4704 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4588 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4460 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4332 - binary_accuracy: 0.6978 - precision: 0.6978 - recall: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4201 - binary_accuracy: 0.7289 - precision: 0.7202 - recall: 1.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4072 - binary_accuracy: 0.7867 - precision: 0.7659 - recall: 1.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3940 - binary_accuracy: 0.8089 - precision: 0.7850 - recall: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3808 - binary_accuracy: 0.8222 - precision: 0.7970 - recall: 1.0000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3673 - binary_accuracy: 0.8400 - precision: 0.8135 - recall: 1.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3541 - binary_accuracy: 0.8578 - precision: 0.8307 - recall: 1.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8756 - precision: 0.8486 - recall: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3275 - binary_accuracy: 0.8933 - precision: 0.8715 - recall: 0.9936\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3141 - binary_accuracy: 0.9022 - precision: 0.8814 - recall: 0.9936\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3011 - binary_accuracy: 0.9022 - precision: 0.8857 - recall: 0.9873\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2889 - binary_accuracy: 0.8978 - precision: 0.8851 - recall: 0.9809\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2788 - binary_accuracy: 0.9022 - precision: 0.8902 - recall: 0.9809\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2683 - binary_accuracy: 0.9067 - precision: 0.9000 - recall: 0.9745\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2592 - binary_accuracy: 0.9067 - precision: 0.9000 - recall: 0.9745\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2509 - binary_accuracy: 0.9200 - precision: 0.9162 - recall: 0.9745\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2436 - binary_accuracy: 0.9200 - precision: 0.9162 - recall: 0.9745\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2363 - binary_accuracy: 0.9111 - precision: 0.9152 - recall: 0.9618\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2305 - binary_accuracy: 0.9111 - precision: 0.9152 - recall: 0.9618\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2252 - binary_accuracy: 0.9156 - precision: 0.9157 - recall: 0.9682\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2210 - binary_accuracy: 0.9156 - precision: 0.9157 - recall: 0.9682\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2165 - binary_accuracy: 0.9156 - precision: 0.9157 - recall: 0.9682\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2125 - binary_accuracy: 0.9156 - precision: 0.9157 - recall: 0.9682\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2103 - binary_accuracy: 0.9289 - precision: 0.9434 - recall: 0.9554\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2076 - binary_accuracy: 0.9378 - precision: 0.9497 - recall: 0.9618\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2042 - binary_accuracy: 0.9244 - precision: 0.9268 - recall: 0.9682\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2019 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2013 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1976 - binary_accuracy: 0.9422 - precision: 0.9500 - recall: 0.9682\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1970 - binary_accuracy: 0.9333 - precision: 0.9494 - recall: 0.9554\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1959 - binary_accuracy: 0.9378 - precision: 0.9554 - recall: 0.9554\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1943 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1968 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1920 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1915 - binary_accuracy: 0.9378 - precision: 0.9497 - recall: 0.9618\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1904 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1891 - binary_accuracy: 0.9378 - precision: 0.9497 - recall: 0.9618\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1883 - binary_accuracy: 0.9289 - precision: 0.9325 - recall: 0.9682\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1876 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1869 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1871 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1864 - binary_accuracy: 0.9333 - precision: 0.9438 - recall: 0.9618\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1865 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1846 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1868 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1836 - binary_accuracy: 0.9378 - precision: 0.9497 - recall: 0.9618\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1838 - binary_accuracy: 0.9378 - precision: 0.9441 - recall: 0.9682\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1833 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1818 - binary_accuracy: 0.9378 - precision: 0.9441 - recall: 0.9682\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1814 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1819 - binary_accuracy: 0.9422 - precision: 0.9557 - recall: 0.9618\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1814 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1805 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1802 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1789 - binary_accuracy: 0.9422 - precision: 0.9500 - recall: 0.9682\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1798 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1818 - binary_accuracy: 0.9378 - precision: 0.9441 - recall: 0.9682\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1777 - binary_accuracy: 0.9378 - precision: 0.9441 - recall: 0.9682\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1776 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1773 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1776 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1770 - binary_accuracy: 0.9378 - precision: 0.9387 - recall: 0.9745\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1767 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1773 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1755 - binary_accuracy: 0.9422 - precision: 0.9500 - recall: 0.9682\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1765 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1746 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1747 - binary_accuracy: 0.9422 - precision: 0.9500 - recall: 0.9682\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1740 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1736 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1739 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1730 - binary_accuracy: 0.9422 - precision: 0.9500 - recall: 0.9682\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1735 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1715 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1717 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1718 - binary_accuracy: 0.9467 - precision: 0.9560 - recall: 0.9682\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1703 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1703 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1695 - binary_accuracy: 0.9511 - precision: 0.9563 - recall: 0.9745\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1695 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1685 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1682 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1677 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1675 - binary_accuracy: 0.9467 - precision: 0.9503 - recall: 0.9745\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1675 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1670 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1666 - binary_accuracy: 0.9422 - precision: 0.9444 - recall: 0.9745\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1132 - binary_accuracy: 0.9615 - precision: 1.0000 - recall: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.11324683576822281,\n",
       " 'binary_accuracy': 0.9615384340286255,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.9473684430122375}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def model_fn():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(6,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[BinaryAccuracy(), Precision(), Recall()],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "history = model.fit(train_data, epochs=EPOCHS)\n",
    "\n",
    "test_scores = model.evaluate(val_data)\n",
    "single_metrics = {\n",
    "    'loss': test_scores[0],\n",
    "    'binary_accuracy': test_scores[1],\n",
    "    'precision': test_scores[2],\n",
    "    'recall': test_scores[3]\n",
    "}\n",
    "single_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Single model metrics---\n",
      "{'loss': 0.11324683576822281, 'binary_accuracy': 0.9615384340286255, 'precision': 1.0, 'recall': 0.9473684430122375}\n",
      "\n",
      "---Federated model metrics---\n",
      "{'binary_accuracy': 0.9223301, 'precision': 0.9350649, 'recall': 0.96, 'loss': 0.22869204, 'num_examples': 103, 'num_batches': 103}\n"
     ]
    }
   ],
   "source": [
    "print(f\"---Single model metrics---\\n{single_metrics}\\n\")\n",
    "print(f\"---Federated model metrics---\\n{dict(federated_metrics['eval'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
